{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HD-OEKQHiSWf"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from torchvision.transforms import Compose\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.init as init\n",
    "import glob\n",
    "import scipy.io as sio\n",
    "from skimage.transform import resize, rescale, rotate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import h5py\n",
    "import time\n",
    "\n",
    "from U_HVED import Discriminator, U_HVEDNet3D\n",
    "from transform import transforms, SegToMask\n",
    "from loss import DiceLoss, WeightedCrossEntropyLoss, GeneralizedDiceLoss, GANLoss, compute_KLD, compute_KLD_drop\n",
    "from metrics import MeanIoU, DiceCoefficient, DiceRegion\n",
    "from evaluation import eval_overlap\n",
    "from BraTSdataset import GBMset\n",
    "from utils import subset_idx, seed_everything, init_weights\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "parallel = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r43I96ViiSW9"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "seed = 20\n",
    "seed_everything(seed)\n",
    "pat_num = 285\n",
    "x_p = np.zeros(pat_num,)\n",
    "# target value\n",
    "y_p = np.zeros(pat_num,)\n",
    "indices = np.arange(pat_num)\n",
    "x_train_p, x_test_p, y_train_p, y_test_p, idx_train, idx_test = train_test_split(x_p, y_p, indices, test_size=0.2, random_state=20)\n",
    "x_train_p, x_valid_p, y_train_p, y_valid_p, idx_train, idx_valid = train_test_split(x_train_p, y_train_p, idx_train, test_size=1/8, random_state=20)\n",
    "\n",
    "train_batch = 3\n",
    "crop_size = 112\n",
    "valid_batch = 15\n",
    "trainset = GBMset(sorted(idx_train), transform=transforms(shift=0.1, flip_prob=0.5, random_crop=crop_size))\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=train_batch,\n",
    "                                          shuffle=True, drop_last=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "validset = GBMset(sorted(idx_valid), transform=transforms(random_crop=crop_size), m_full=True)\n",
    "validloader = torch.utils.data.DataLoader(validset, batch_size=valid_batch,\n",
    "                                          shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "ov_trainset = GBMset(sorted(idx_train), transform=transforms())\n",
    "ov_trainloader = torch.utils.data.DataLoader(ov_trainset, batch_size=1,\n",
    "                                          shuffle=False, num_workers=4)\n",
    "\n",
    "ov_validset = GBMset(sorted(idx_valid), transform=transforms())\n",
    "ov_validloader = torch.utils.data.DataLoader(ov_validset, batch_size=1,\n",
    "                                          shuffle=False, num_workers=4)\n",
    "\n",
    "ov_testset = GBMset(sorted(idx_test), transform=transforms())\n",
    "ov_testloader = torch.utils.data.DataLoader(ov_testset, batch_size=1,\n",
    "                                          shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 869
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 96853,
     "status": "ok",
     "timestamp": 1589246071284,
     "user": {
      "displayName": "정승완",
      "photoUrl": "",
      "userId": "15763642359574431598"
     },
     "user_tz": -540
    },
    "id": "9I3XT-aWiSXU",
    "outputId": "36397e14-4952-48a4-e734-0e5062aa539c"
   },
   "outputs": [],
   "source": [
    "n_class = 3\n",
    "channel = 4\n",
    "\n",
    "model = U_HVEDNet3D(1, 3,  multi_stream = 4, fusion_level = 4,\n",
    "                    recon_skip=True, MVAE_reduction=True, final_sigmoid=True, f_maps=16, layer_order='ilc')\n",
    "model.apply(init_weights)\n",
    "disc = Discriminator(in_channels=7, ks=4, strides=[1,2,2,2])\n",
    "disc.apply(init_weights)\n",
    "if parallel:\n",
    "    model = nn.DataParallel(model)\n",
    "    disc = nn.DataParallel(disc)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "disc.to(device)\n",
    "print_every = 20\n",
    "num_epochs= 300\n",
    "validate_every = 20\n",
    "\n",
    "learning_rate = 0.0001\n",
    "weight_decay = 0.00001\n",
    "alpha = 0.1 # for adv loss\n",
    "beta = 0.1 # for recon loss\n",
    "train_loss, train_dice = [], []\n",
    "valid_loss, valid_dice = [], []\n",
    "\n",
    "dice_loss = DiceLoss()\n",
    "wce_loss = ce\n",
    "gan_loss = GANLoss().to(device)\n",
    "l1_loss = nn.L1Loss()\n",
    "l2_loss = nn.MSELoss()\n",
    "dc = DiceCoefficient()\n",
    "dcR = DiceRegion()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "optimizer_g = optim.Adam(model.parameters(), lr=0.0001, weight_decay=weight_decay)\n",
    "optimizer_d = optim.Adam(disc.parameters(), lr=0.0001, weight_decay=weight_decay)\n",
    "\n",
    "lambda1 = lambda epoch: (1 - epoch / num_epochs)**0.9\n",
    "sch = lr_scheduler.LambdaLR(optimizer, lr_lambda=[lambda1])\n",
    "sch_g = lr_scheduler.LambdaLR(optimizer_g, lr_lambda=[lambda1])\n",
    "sch_d = lr_scheduler.LambdaLR(optimizer_d, lr_lambda=[lambda1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 33990116,
     "status": "ok",
     "timestamp": 1589140637881,
     "user": {
      "displayName": "정승완",
      "photoUrl": "",
      "userId": "15763642359574431598"
     },
     "user_tz": -540
    },
    "id": "C4Gzb1iWiSXv",
    "outputId": "2b9bc715-9cb2-491e-bc87-a353fefb0e9a"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    tr_dice = 0.0\n",
    "    tr_wt_dice = 0.0\n",
    "    tr_tc_dice = 0.0\n",
    "    tr_ec_dice = 0.0\n",
    "    \n",
    "    model.train()\n",
    "    disc.train()\n",
    "    start_perf_counter = time.perf_counter()\n",
    "    start_process_time = time.process_time()\n",
    "    for x_batch, x_m_batch, mask_batch, _ in trainloader:\n",
    "        x_batch = x_batch.float().to('cuda')\n",
    "        x_m_batch = x_m_batch.float().to('cuda')\n",
    "        mask_batch = mask_batch.float().to('cuda')\n",
    "        \n",
    "        drop = torch.sum(x_m_batch, [2,3,4]) == 0\n",
    "        subset_size = np.random.choice(range(1,4), 1)\n",
    "        subset_index_list = subset_idx(subset_size)\n",
    "        f_outputs, _, f_recon_outputs = model(x_batch, [14], recon=True)\n",
    "        m_outputs, (mu, logvar), m_recon_outputs = model(x_batch, subset_index_list, recon=True)\n",
    "        \n",
    "        # (1) Update G network about mask + MVAE + GAN\n",
    "        dice = dice_loss(f_outputs, mask_batch)\n",
    "        m_dice = dice_loss(m_outputs, mask_batch)\n",
    "        recon = l2_loss(m_recon_outputs, x_batch)\n",
    "        sum_inter_KLD = 0.0\n",
    "        sum_prior_KLD = 0.0\n",
    "        subset_index_list = subset_index_list\n",
    "        for level in range(len(mu)):\n",
    "            prior_KLD = compute_KLD(mu[level], logvar[level], subset_index_list)\n",
    "            sum_prior_KLD += prior_KLD\n",
    "        KLD = 1/len(mu)*sum_prior_KLD\n",
    "        \n",
    "        syn_f_x = f_recon_outputs.detach()\n",
    "        syn_m_x = m_recon_outputs\n",
    "        f_weight = f_outputs.detach()\n",
    "        f_weight = torch.where(f_weight > 0.5, f_weight, torch.zeros_like(f_weight))\n",
    "        f_nested_w = f_weight.mean(1)\n",
    "        \n",
    "        m_weight = m_outputs.detach()\n",
    "        m_weight = torch.where(m_weight > 0.5, m_weight, torch.zeros_like(m_weight))\n",
    "        m_nested_w = m_weight.mean(1)\n",
    "        \n",
    "        atten_f_x = syn_f_x*(1 + f_nested_w.unsqueeze(1))\n",
    "        atten_m_x = syn_m_x*(1 + m_nested_w.unsqueeze(1))\n",
    "        pred_fake = disc(torch.cat([m_outputs, atten_m_x], 1))\n",
    "        g_gan = gan_loss(pred_fake, True)\n",
    "        loss = dice + 0.4*m_dice + beta*recon + beta*KLD + alpha*g_gan\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # (2) Update D network\n",
    "        # train with fake(missing)\n",
    "#         pred_fake = disc(m_outputs.detach())\n",
    "        pred_fake = disc(torch.cat([m_outputs.detach(), atten_m_x.detach()], 1))\n",
    "        loss_d_fake = gan_loss(pred_fake, False)\n",
    "\n",
    "        # train with real(full)\n",
    "#         pred_real = disc(f_outputs.detach())\n",
    "        pred_real = disc(torch.cat([f_outputs.detach(), atten_f_x.detach()], 1))\n",
    "        loss_d_real = gan_loss(pred_real, True)\n",
    "        \n",
    "        # Combined D loss\n",
    "        loss_d = alpha*(loss_d_fake + loss_d_real) * 0.5\n",
    "\n",
    "        optimizer_d.zero_grad()\n",
    "        loss_d.backward()\n",
    "        optimizer_d.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        avg_dice = dc(f_outputs.detach(), mask_batch.detach())\n",
    "        wt_dice = dcR(f_outputs.detach(), mask_batch.detach())\n",
    "        tc_dice = dcR(f_outputs.detach(), mask_batch.detach(), 'TC')\n",
    "        ec_dice = dcR(f_outputs.detach(), mask_batch.detach(), 'EC')\n",
    "        tr_dice += avg_dice.item()\n",
    "        tr_wt_dice += wt_dice.item()\n",
    "        tr_tc_dice += tc_dice.item()\n",
    "        tr_ec_dice += ec_dice.item()\n",
    "    \n",
    "    perf_counter = time.perf_counter() - start_perf_counter\n",
    "    process_time = time.process_time() - start_process_time\n",
    "    epoch_loss /= len(trainloader)\n",
    "    tr_dice /= len(trainloader)\n",
    "    tr_wt_dice /= len(trainloader)\n",
    "    tr_tc_dice /= len(trainloader)\n",
    "    tr_ec_dice /= len(trainloader)\n",
    "    \n",
    "    train_loss.append(epoch_loss)\n",
    "    train_dice.append(tr_dice)\n",
    "    \n",
    "    va_loss = 0.0\n",
    "    va_dice = 0.0\n",
    "    va_wt_dice = 0.0\n",
    "    va_tc_dice = 0.0\n",
    "    va_ec_dice = 0.0\n",
    "    va_wt_dice_m = 0.0\n",
    "    va_tc_dice_m = 0.0\n",
    "    va_ec_dice_m = 0.0\n",
    "    \n",
    "    if i<5 or (i + 1) % validate_every == 0:\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            disc.eval()\n",
    "            # Valid accuracy\n",
    "            for x_batch, x_m_batch, mask_batch, _ in validloader:\n",
    "\n",
    "                x_batch = x_batch.float().to('cuda')\n",
    "                x_m_batch = x_m_batch.float().to('cuda')\n",
    "                mask_batch = mask_batch.long().to('cuda')\n",
    "                pred, _ = model(x_batch, valid=True)\n",
    "                pred_m, _ = model(x_m_batch, instance_missing=True, valid=True)\n",
    "                dice = dice_loss(pred, mask_batch)\n",
    "                loss = dice\n",
    "\n",
    "                va_loss += loss.item()\n",
    "                avg_dice = dc(pred.detach(), mask_batch.detach())\n",
    "                wt_dice = dcR(pred.detach(), mask_batch.detach())\n",
    "                tc_dice = dcR(pred.detach(), mask_batch.detach(), 'TC')\n",
    "                ec_dice = dcR(pred.detach(), mask_batch.detach(), 'EC')\n",
    "                wt_dice_m = dcR(pred_m.detach(), mask_batch.detach())\n",
    "                tc_dice_m = dcR(pred_m.detach(), mask_batch.detach(), 'TC')\n",
    "                ec_dice_m = dcR(pred_m.detach(), mask_batch.detach(), 'EC')\n",
    "                \n",
    "                va_dice += avg_dice.item()\n",
    "                va_wt_dice += wt_dice.item()\n",
    "                va_tc_dice += tc_dice.item()\n",
    "                va_ec_dice += ec_dice.item()\n",
    "                va_wt_dice_m += wt_dice_m.item()\n",
    "                va_tc_dice_m += tc_dice_m.item()\n",
    "                va_ec_dice_m += ec_dice_m.item()\n",
    "\n",
    "\n",
    "            va_loss /= len(validloader)\n",
    "            va_dice /= len(validloader)\n",
    "            va_wt_dice /= len(validloader)\n",
    "            va_tc_dice /= len(validloader)\n",
    "            va_ec_dice /= len(validloader)\n",
    "            va_wt_dice_m /= len(validloader)\n",
    "            va_tc_dice_m /= len(validloader)\n",
    "            va_ec_dice_m /= len(validloader)\n",
    "\n",
    "            valid_loss.append(va_loss)\n",
    "            valid_dice.append(va_dice)\n",
    "            \n",
    "    if i == 0:\n",
    "        print(f'perf_counter per epoch : {time.strftime(\"%H:%M:%S\", time.gmtime(perf_counter))}')\n",
    "        print(f'process_time per epoch : {time.strftime(\"%H:%M:%S\", time.gmtime(process_time))}')\n",
    "        \n",
    "    if i<5 or (i + 1) % print_every == 0:\n",
    "        print('Epoch [{}/{}], Train_Loss: {:.4f}, Train_dice: {:.4f}, Train_wt_dice: {:.4f}, Train_tc_dice: {:.4f}, Train_ec_dice: {:.4f},\\\n",
    "              \\nValid_Loss: {:.4f}, Valid_dice: {:.4f}, Valid_wt_dice: {:.4f}, Valid_tc_dice: {:.4f}, Valid_ec_dice: {:.4f},\\\n",
    "              \\nValid_wt_dice: {:.4f}, Valid_tc_dice: {:.4f}, Valid_ec_dice: {:.4f}'\n",
    "              .format(i + 1, num_epochs, epoch_loss, tr_dice, tr_wt_dice, tr_tc_dice, tr_ec_dice,\n",
    "                      va_loss, va_dice, va_wt_dice, va_tc_dice, va_ec_dice,\n",
    "                     va_wt_dice_m, va_tc_dice_m, va_ec_dice_m))\n",
    "        \n",
    "    if (i + 1) == num_epochs or (i + 1) % 20 == 0:\n",
    "        print(eval_overlap(ov_testloader, model, patch_size=crop_size, overlap_stepsize=crop_size//2, batch_size=valid_batch, num_classes=3))\n",
    "    if (i + 1) == num_epochs or (i + 1) % 80 == 0:\n",
    "        print(eval_overlap(ov_validloader, model, patch_size=crop_size, overlap_stepsize=crop_size//2, batch_size=valid_batch, num_classes=3))\n",
    "    if (i + 1) == num_epochs or (i + 1) % 80 == 0:\n",
    "        print(eval_overlap(ov_trainloader, model, patch_size=crop_size, overlap_stepsize=crop_size//2, batch_size=valid_batch, num_classes=3))\n",
    "    if (i+1) >= 160 and (i + 1) % 10 == 0:\n",
    "        save_dir = 'model/test_resunet_u-hved_attenjointgan(0.1)_md(0.4)_f16_112_300/'\n",
    "        if parallel:\n",
    "            m = model.module\n",
    "        else:\n",
    "            m = model\n",
    "        torch.save(m.state_dict(), save_dir + str(i+1) + '.pth')#, _use_new_zipfile_serialization=False)\n",
    "        \n",
    "    sch.step()\n",
    "    sch_d.step()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "example_DA_new8_2_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
